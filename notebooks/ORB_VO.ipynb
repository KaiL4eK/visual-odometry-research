{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/yanii/kitti-pcl/blob/master/KITTI_README.TXT  \n",
    "- http://ksimek.github.io/2013/08/13/intrinsic/\n",
    "- http://www.cvlibs.net/publications/Geiger2013IJRR.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import quaternion as quat\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KITTIData(object):\n",
    "    def __init__(self, dataset_dir, sequence_id='00'):\n",
    "        SEQUENCE_DIR = os.path.join(DATASET_DIR, 'sequences', sequence_id)\n",
    "        POSES_DIR = os.path.join(DATASET_DIR, 'poses')\n",
    "\n",
    "        POSE_PATH = os.path.join(POSES_DIR, f'{sequence_id}.txt')\n",
    "        TIMES_PATH = os.path.join(SEQUENCE_DIR, 'times.txt')\n",
    "        CALIB_PATH = os.path.join(SEQUENCE_DIR, 'calib.txt')\n",
    "        \n",
    "        self.poses = self._load_poses(POSE_PATH)\n",
    "        self.times = self._load_times(TIMES_PATH)\n",
    "        \n",
    "        self._load_calib(CALIB_PATH)\n",
    "        \n",
    "        print('Intrinsics:')\n",
    "        for name, intr in self.intricsics.items():\n",
    "            print(f'{name}:\\n{intr}')\n",
    "        print('Extrinsics to cam0:')\n",
    "        for name, extr in self.cam0_extrinsics.items():\n",
    "            print(f'{name}:\\n{extr}')\n",
    "        print('Extrinsics to velo:')\n",
    "        for name, extr in self.velo_extrinsics.items():\n",
    "            print(f'{name}:\\n{extr}')\n",
    "        print('Baselines:')\n",
    "        print(self.baselines)\n",
    "\n",
    "        \n",
    "        self.LEFT_IMAGES_DIR = os.path.join(SEQUENCE_DIR, 'image_2')\n",
    "        self.RIGHT_IMAGES_DIR = os.path.join(SEQUENCE_DIR, 'image_3')\n",
    "\n",
    "        self.images = [fname for fname in os.listdir(self.LEFT_IMAGES_DIR) if fname.endswith('.png')]\n",
    "        \n",
    "        print(f'Sequence {sequence_id} length: {len(self.poses)}')\n",
    "        \n",
    "        # Sanity check!\n",
    "        for i in range(len(self.poses)):\n",
    "            fname = self._get_image_fname(i)\n",
    "            if fname not in self.images:\n",
    "                raise Exception(f'File with name {fname} not exists in {IMAGES_DIR}')\n",
    "        # After this check we can use idx to generate fpaths\n",
    "        \n",
    "    def _get_image_fname(self, idx):\n",
    "        return f'{idx:06}.png'\n",
    "        \n",
    "    def _load_times(self, fpath):\n",
    "        times_data = np.fromfile(fpath, sep='\\n')\n",
    "        return times_data\n",
    "    \n",
    "    def _load_poses(self, fpath):\n",
    "        poses_data = np.fromfile(fpath, sep=' ')\n",
    "        poses_data = poses_data.reshape((-1, 3, 4))\n",
    "        # Convert to 4x4 matrices\n",
    "        last_row = np.array([[[0,0,0,1]]])\n",
    "        last_rows = np.repeat(last_row, axis=0, repeats=poses_data.shape[0])\n",
    "        poses_data = np.hstack((poses_data, last_rows))\n",
    "        return poses_data\n",
    "    \n",
    "    # Based on\n",
    "    # https://github.com/utiasSTARS/pykitti/blob/d3e1bb81676e831886726cc5ed79ce1f049aef2c/pykitti/odometry.py#L145\n",
    "    def _load_calib(self, fpath):\n",
    "        filedata = {}\n",
    "        with open(fpath) as f:\n",
    "            while True:\n",
    "                line = f.readline()\n",
    "                if not line:\n",
    "                    break\n",
    "                \n",
    "                name, info = line.split(':')\n",
    "                calib_data = np.fromstring(info, sep=' ')\n",
    "                filedata[name] = calib_data.reshape(3, 4)\n",
    "\n",
    "        self.intricsics = {}\n",
    "        self.intricsics['K_cam0'] = filedata['P0'][0:3, 0:3]\n",
    "        self.intricsics['K_cam1'] = filedata['P1'][0:3, 0:3]\n",
    "        self.intricsics['K_cam2'] = filedata['P2'][0:3, 0:3]\n",
    "        self.intricsics['K_cam3'] = filedata['P3'][0:3, 0:3]\n",
    "        \n",
    "\n",
    "        self.cam0_extrinsics = {}\n",
    "        self.cam0_extrinsics['T1'] = np.eye(4)\n",
    "        self.cam0_extrinsics['T1'][0, 3] = filedata['P1'][0,3] / filedata['P1'][0,0]\n",
    "        self.cam0_extrinsics['T2'] = np.eye(4)\n",
    "        self.cam0_extrinsics['T2'][0, 3] = filedata['P2'][0,3] / filedata['P2'][0,0]\n",
    "        self.cam0_extrinsics['T3'] = np.eye(4)\n",
    "        self.cam0_extrinsics['T3'][0, 3] = filedata['P3'][0,3] / filedata['P3'][0,0]\n",
    "        \n",
    "        self.velo_extrinsics = {}\n",
    "        self.velo_extrinsics['T0'] = np.reshape(filedata['Tr'], (3, 4))\n",
    "        self.velo_extrinsics['T0'] = np.vstack([self.velo_extrinsics['T0'], [0, 0, 0, 1]])\n",
    "        self.velo_extrinsics['T1'] = self.cam0_extrinsics['T1'].dot(self.velo_extrinsics['T0'])\n",
    "        self.velo_extrinsics['T2'] = self.cam0_extrinsics['T2'].dot(self.velo_extrinsics['T0'])\n",
    "        self.velo_extrinsics['T3'] = self.cam0_extrinsics['T3'].dot(self.velo_extrinsics['T0'])        \n",
    "            \n",
    "        p_cam = np.array([0, 0, 0, 1])\n",
    "        p_velo2 = np.linalg.inv(self.velo_extrinsics['T2']).dot(p_cam)\n",
    "        p_velo3 = np.linalg.inv(self.velo_extrinsics['T3']).dot(p_cam)\n",
    "\n",
    "        self.baselines = {}\n",
    "        self.baselines['rgb'] = np.linalg.norm(p_velo3 - p_velo2)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.poses)-1\n",
    "\n",
    "    def _get_transform(self, idx):\n",
    "        c_idx = idx\n",
    "        n_idx = idx+1\n",
    "        \n",
    "        c_pose = self.poses[c_idx]\n",
    "        n_pose = self.poses[n_idx]\n",
    "\n",
    "        local_dtrans = np.linalg.inv(c_pose) @ n_pose[:, 3]\n",
    "\n",
    "        quat_c = quat.from_rotation_matrix(c_pose[:3,:3])\n",
    "        quat_n = quat.from_rotation_matrix(n_pose[:3,:3])\n",
    "        quat_t = quat_c.inverse() * quat_n\n",
    "\n",
    "        gt_quat_t_ar = quat.as_float_array(quat_t).astype(np.float32)\n",
    "        gt_trans = local_dtrans[:3].astype(np.float32)\n",
    "        return gt_quat_t_ar, gt_trans\n",
    "    \n",
    "    def _intrinsics_dict(self, mtrx):\n",
    "        return {\n",
    "            'cx': mtrx[0,2],\n",
    "            'cy': mtrx[1,2],\n",
    "            'fx': mtrx[0,0],\n",
    "            'fy': mtrx[1,1]\n",
    "        }\n",
    "    \n",
    "    def get_color_intrinsics_dicts(self):\n",
    "        left = _intrinsics_dict(self.intricsics['K_cam2'])\n",
    "        right = _intrinsics_dict(self.intricsics['K_cam3'])\n",
    "        return left, right\n",
    "    \n",
    "    def get_color_left_Q_matrix(self):\n",
    "        # Left\n",
    "        intr = self._intrinsics_dict(self.intricsics['K_cam2'])\n",
    "        baseline = self.baselines['rgb']\n",
    "        \n",
    "        Q = np.array([\n",
    "            [1, 0, 0, -intr['cx']],\n",
    "            [0, 1, 0, -intr['cy']],\n",
    "            [0, 0, 0, intr['fx']],\n",
    "            [0, 0, -1/baseline, 0]\n",
    "        ])\n",
    "        \n",
    "        return Q\n",
    "\n",
    "    def get_color_images(self, idx):\n",
    "        fname = self._get_image_fname(idx)\n",
    "        left_img_fpath = os.path.join(self.LEFT_IMAGES_DIR, fname)\n",
    "        right_img_fpath = os.path.join(self.RIGHT_IMAGES_DIR, fname)\n",
    "        l_img = cv2.imread(left_img_fpath)\n",
    "        l_img = cv2.cvtColor(l_img, cv2.COLOR_BGR2RGB)\n",
    "        r_img = cv2.imread(right_img_fpath)\n",
    "        r_img = cv2.cvtColor(r_img, cv2.COLOR_BGR2RGB)\n",
    "        return l_img, r_img\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        c_idx = idx\n",
    "        n_idx = idx+1\n",
    "        \n",
    "        c_pose = self.poses[c_idx]\n",
    "        n_pose = self.poses[n_idx]\n",
    "\n",
    "        c_img_fpath = os.path.join(\n",
    "            self.IMAGES_DIR, \n",
    "            self._get_image_fname(c_idx)\n",
    "        )\n",
    "        n_img_fpath = os.path.join(\n",
    "            self.IMAGES_DIR, \n",
    "            self._get_image_fname(n_idx)\n",
    "        )\n",
    "        \n",
    "        c_img = cv2.imread(c_img_fpath)\n",
    "        c_img = cv2.cvtColor(c_img, cv2.COLOR_BGR2RGB)\n",
    "        n_img = cv2.imread(n_img_fpath)\n",
    "        n_img = cv2.cvtColor(n_img, cv2.COLOR_BGR2RGB)\n",
    "        gt_quat_t_ar, gt_trans = self._get_transform(idx)\n",
    "        return c_img, n_img, gt_quat_t_ar, gt_trans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_matches(img1, kp1, img2, kp2, matches, color=None): \n",
    "    \"\"\"Draws lines between matching keypoints of two images.  \n",
    "    Keypoints not in a matching pair are not drawn.\n",
    "    Places the images side by side in a new image and draws circles \n",
    "    around each keypoint, with line segments connecting matching pairs.\n",
    "    You can tweak the r, thickness, and figsize values as needed.\n",
    "    Args:\n",
    "        img1: An openCV image ndarray in a grayscale or color format.\n",
    "        kp1: A list of cv2.KeyPoint objects for img1.\n",
    "        img2: An openCV image ndarray of the same format and with the same \n",
    "        element type as img1.\n",
    "        kp2: A list of cv2.KeyPoint objects for img2.\n",
    "        matches: A list of DMatch objects whose trainIdx attribute refers to \n",
    "        img1 keypoints and whose queryIdx attribute refers to img2 keypoints.\n",
    "        color: The color of the circles and connecting lines drawn on the images.  \n",
    "        A 3-tuple for color images, a scalar for grayscale images.  If None, these\n",
    "        values are randomly generated.  \n",
    "    \"\"\"\n",
    "    # We're drawing them side by side.  Get dimensions accordingly.\n",
    "    # Handle both color and grayscale images.\n",
    "    if len(img1.shape) == 3:\n",
    "        new_shape = (img1.shape[0]+img2.shape[0], max(img1.shape[1], img2.shape[1]), img1.shape[2])\n",
    "    elif len(img1.shape) == 2:\n",
    "        new_shape = (img1.shape[0]+img2.shape[0], max(img1.shape[1], img2.shape[1]))\n",
    "    new_img = np.zeros(new_shape, type(img1.flat[0]))  \n",
    "    # Place images onto the new image.\n",
    "    new_img[0:img1.shape[0],0:img1.shape[1]] = img1\n",
    "    new_img[img1.shape[0]:img1.shape[0]+img2.shape[0],0:img2.shape[1]] = img2\n",
    "    \n",
    "    # Draw lines between matches.  Make sure to offset kp coords in second image appropriately.\n",
    "    r = 10\n",
    "    thickness = 2\n",
    "    if color:\n",
    "        c = color\n",
    "    else:\n",
    "        # Generate random color for RGB/BGR and grayscale images as needed.\n",
    "        c = np.random.randint(0,256,3) if len(img1.shape) == 3 else np.random.randint(0,256)\n",
    "        c = (0, 255, 0)\n",
    "    for m in matches:\n",
    "        # So the keypoint locs are stored as a tuple of floats.  cv2.line(), like most other things,\n",
    "        # wants locs as a tuple of ints.\n",
    "        end1 = tuple(np.round(kp1[m.queryIdx].pt).astype(int))\n",
    "        end2 = tuple(np.round(kp2[m.trainIdx].pt).astype(int) + np.array([0, img1.shape[0]]))\n",
    "        cv2.line(new_img, end1, end2, c, thickness)\n",
    "        cv2.circle(new_img, end1, r, c, thickness)\n",
    "        cv2.circle(new_img, end2, r, c, thickness)\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.join('../', 'data/KITTI/dataset')\n",
    "dataset = KITTIData(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stereovision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_img, r_img = dataset.get_color_images(20)\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(l_img)\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(r_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_matcher = cv2.StereoBM_create(numDisparities=112, blockSize=15)\n",
    "\n",
    "# wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "# right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "left_matcher.setMinDisparity(0)\n",
    "left_matcher.setSpeckleRange(20)\n",
    "left_matcher.setSpeckleWindowSize(100)\n",
    "left_matcher.setDisp12MaxDiff(64)\n",
    "left_matcher.setUniquenessRatio(5)\n",
    "left_matcher.setPreFilterCap(1)\n",
    "left_matcher.setPreFilterSize(5)\n",
    "left_matcher.setTextureThreshold(5)\n",
    "\n",
    "l_img_gray = cv2.cvtColor(l_img, cv2.COLOR_RGB2GRAY)\n",
    "r_img_gray = cv2.cvtColor(r_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "l_disp = left_matcher.compute(l_img_gray, r_img_gray)\n",
    "# r_disp = right_matcher.compute(r_img_gray, l_img_gray)\n",
    "\n",
    "# wls_filter.setLambda(8000)\n",
    "# wls_filter.setSigmaColor(8000)\n",
    "# # wls_filter->filter(left_disp,left,filtered_disp,right_disp);\n",
    "# wls_filter.filter(l_disp, l_img_gray, )\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(l_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_matcher = cv2.StereoSGBM_create(\n",
    "    minDisparity=0,\n",
    "    numDisparities=112, \n",
    "    blockSize=15,\n",
    "    P1=0,\n",
    "    P2=0,\n",
    "    disp12MaxDiff=64,\n",
    "    preFilterCap=1,\n",
    "    uniquenessRatio=5,\n",
    "    speckleWindowSize=100,\n",
    "    speckleRange=20\n",
    ")\n",
    "\n",
    "# wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)\n",
    "# right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)\n",
    "\n",
    "l_img_gray = cv2.cvtColor(l_img, cv2.COLOR_RGB2GRAY)\n",
    "r_img_gray = cv2.cvtColor(r_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "l_disp = left_matcher.compute(l_img_gray, r_img_gray)\n",
    "# r_disp = right_matcher.compute(r_img_gray, l_img_gray)\n",
    "\n",
    "# wls_filter.setLambda(8000)\n",
    "# wls_filter.setSigmaColor(8000)\n",
    "# # wls_filter->filter(left_disp,left,filtered_disp,right_disp);\n",
    "# wls_filter.filter(l_disp, l_img_gray, )\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(l_disp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output is always int16\n",
    "disp = l_disp.astype(np.float32) / 16.0\n",
    "\n",
    "Q_left = dataset.get_color_left_Q_matrix()\n",
    "\n",
    "points = cv2.reprojectImageTo3D(disp, Q_left).reshape(-1, 3)\n",
    "\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 25\n",
    "c_img, _ = dataset.get_color_images(idx)\n",
    "n_img, _ = dataset.get_color_images(idx+1)\n",
    "\n",
    "orb = cv2.ORB_create(\n",
    "    nfeatures=500,\n",
    "    scaleFactor=1.2,\n",
    "    nlevels=8,\n",
    "    edgeThreshold=31,\n",
    "    firstLevel=0,\n",
    "    WTA_K=2,\n",
    "    scoreType=cv2.ORB_HARRIS_SCORE,\n",
    "    patchSize=31,\n",
    "    fastThreshold=10\n",
    ")\n",
    "c_kp, c_des = orb.detectAndCompute(c_img, None)\n",
    "n_kp, n_des = orb.detectAndCompute(n_img, None)\n",
    "\n",
    "c_img_canvas = c_img.copy()\n",
    "n_img_canvas = n_img.copy()\n",
    "cv2.drawKeypoints(c_img_canvas, c_kp, c_img_canvas, color=(0,255,0), flags=0)\n",
    "cv2.drawKeypoints(n_img_canvas, n_kp, n_img_canvas, color=(0,255,0), flags=0)\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(c_img_canvas)\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(n_img_canvas)\n",
    "print('Trans', trns)\n",
    "print('Quat', quaternion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict(maxCorners=100,\n",
    "                      qualityLevel=0.3,\n",
    "                      minDistance=7,\n",
    "                      blockSize=7)\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict(winSize=(15, 15),\n",
    "                 maxLevel=2,\n",
    "                 criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "c_img_gray = cv2.cvtColor(c_img, cv2.COLOR_RGB2GRAY)\n",
    "n_img_gray = cv2.cvtColor(n_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "c_feat_corners = cv2.goodFeaturesToTrack(c_img_gray, mask=None, **feature_params)\n",
    "\n",
    "c_img_canvas = c_img.copy()\n",
    "for p in c_feat_corners:\n",
    "    cv2.circle(c_img_canvas, tuple(p[0]), 5, (20, 255, 20), 2)\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(c_img_canvas)\n",
    "\n",
    "n_feat_corners, st, err = cv2.calcOpticalFlowPyrLK(c_img_gray, n_img_gray, c_feat_corners, None, **lk_params)\n",
    "n_img_canvas = n_img.copy()\n",
    "for p in n_feat_corners:\n",
    "    cv2.circle(n_img_canvas, tuple(p[0]), 5, (20, 255, 20), 2)\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(n_img_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "matches = bf.match(c_des, n_des)\n",
    "matches = sorted(matches, key = lambda x:x.distance)\n",
    "\n",
    "# Filter with distance larger than 35\n",
    "matches = [m for m in matches if m.distance < 35]\n",
    "\n",
    "# img_matched = cv2.drawMatches(c_img, c_kp, n_img, n_kp, matches[:10], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n",
    "img_matched = draw_matches(c_img, c_kp, n_img, n_kp, matches)\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "plt.imshow(img_matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
