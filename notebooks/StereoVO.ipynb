{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Main KITTI readme (old): https://github.com/yanii/kitti-pcl/blob/master/KITTI_README.TXT  \n",
    "- About Intrinsics: http://ksimek.github.io/2013/08/13/intrinsic/\n",
    "- Car scheme: http://www.cvlibs.net/publications/Geiger2013IJRR.pdf\n",
    "- https://avisingh599.github.io/vision/visual-odometry-full/\n",
    "- Image with reprojection: https://yadi.sk/i/JAIIsbP5dHAELg\n",
    "- https://github.com/cgarg92/Stereo-visual-odometry\n",
    "- http://www.cs.toronto.edu/~urtasun/courses/CSC2541/03_odometry.pdf\n",
    "- https://dsp.stackexchange.com/questions/2736/step-by-step-camera-pose-estimation-for-visual-tracking-and-planar-markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from shared.data import KITTIData,  VisualOdometry, draw_matches, draw_keypoints\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "print(mpl.style.available)\n",
    "mpl.style.use('grayscale')\n",
    "\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# https://github.com/matplotlib/ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_DIR = os.path.join('../', 'data/KITTI/dataset')\n",
    "dataset = KITTIData(DATASET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_idx = 105\n",
    "c_l_img, c_r_img = dataset.get_images(frame_idx)\n",
    "n_l_img, n_r_img = dataset.get_images(frame_idx+1)\n",
    "Q_left = dataset.get_left_Q_matrix()\n",
    "gt_transform = dataset._get_transform_mtrx(frame_idx)\n",
    "gt_pose_transform = dataset.get_poses_transform(frame_idx)\n",
    "c_pose = dataset.get_poses()[frame_idx]\n",
    "C_left, _ = dataset.get_ะก_matrix()\n",
    "\n",
    "print(gt_transform)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.imshow(c_l_img)\n",
    "ax2.imshow(n_l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo = VisualOdometry()\n",
    "c_depth_frame = vo.process_depth(c_l_img, c_r_img, Q_left)\n",
    "n_depth_frame = vo.process_depth(n_l_img, n_r_img, Q_left)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.imshow(c_depth_frame[:,:,2])\n",
    "ax2.imshow(n_depth_frame[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_feats, n_feats = vo.get_features(c_l_img, n_l_img)\n",
    "\n",
    "c_img_canvas = c_l_img.copy()\n",
    "n_img_canvas = n_l_img.copy()\n",
    "draw_keypoints(c_img_canvas, n_img_canvas, c_feats, n_feats)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.imshow(c_img_canvas)\n",
    "ax2.imshow(n_img_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_3d_features(c_pnts3d, n_pnts3d, C_left):\n",
    "    P_left = np.hstack((C_left, np.transpose([[0, 0, 0]])))\n",
    "\n",
    "    c_pnts_2d = vo.reproject_3d_to_2d(c_pnts3d, P_left)\n",
    "    n_pnts_2d = vo.reproject_3d_to_2d(n_pnts3d, P_left)\n",
    "\n",
    "    c_img_canvas = c_l_img.copy()\n",
    "    n_img_canvas = n_l_img.copy()\n",
    "    # Check after clique and projection\n",
    "    draw_keypoints(c_img_canvas, n_img_canvas, c_pnts_2d, n_pnts_2d)\n",
    "    # # Rendering valid features\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    ax1.imshow(c_img_canvas)\n",
    "    ax2.imshow(n_img_canvas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get 3D points \n",
    "c_pnts_3d, c_ft_idxs = vo.reproject_2d_to_3d_points(c_feats, c_depth_frame)\n",
    "n_pnts_3d, n_ft_idxs = vo.reproject_2d_to_3d_points(n_feats, n_depth_frame)\n",
    "\n",
    "ft_idxs = c_ft_idxs & n_ft_idxs\n",
    "\n",
    "c_pnts_3d = c_pnts_3d[ft_idxs]\n",
    "n_pnts_3d = n_pnts_3d[ft_idxs]\n",
    "\n",
    "# c_img_canvas = c_l_img.copy()\n",
    "# n_img_canvas = n_l_img.copy()\n",
    "# draw_keypoints(c_img_canvas, n_img_canvas, c_feats[ft_idxs], n_feats[ft_idxs])\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=[15,9])\n",
    "# ax1.imshow(c_img_canvas)\n",
    "# ax2.imshow(n_img_canvas)\n",
    "\n",
    "transform = vo.get_transform(c_pnts_3d, n_pnts_3d, C_left, type_='PnPRansac')\n",
    "# print(transform[:3,:3], transform[:3,3])\n",
    "# print(gt_pose_transform[:3,:3], gt_pose_transform[:3,3])\n",
    "\n",
    "n_pose = vo.get_next_pose(transform, c_pose)\n",
    "\n",
    "pred_pose_transform = n_pose @ np.linalg.inv(c_pose)\n",
    "# print(pred_pose_transform[:3,:3], pred_pose_transform[:3,3])\n",
    "err = np.abs(gt_pose_transform-pred_pose_transform)\n",
    "print(err[:3,:3])\n",
    "print(err[:3,3])\n",
    "\n",
    "show_3d_features(c_pnts_3d, n_pnts_3d, C_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Filter \n",
    "cl_idxs, _ = vo.max_clique_filter(c_pnts_3d, n_pnts_3d)\n",
    "c_pnts_3d_cl = c_pnts_3d[cl_idxs]\n",
    "n_pnts_3d_cl = n_pnts_3d[cl_idxs]\n",
    "\n",
    "# c_img_canvas = c_l_img.copy()\n",
    "# n_img_canvas = n_l_img.copy()\n",
    "# draw_keypoints(c_img_canvas, n_img_canvas, c_feats[cl_idxs], n_feats[cl_idxs])\n",
    "# fig, (ax1, ax2) = plt.subplots(2, 1, figsize=[15,9])\n",
    "# ax1.imshow(c_img_canvas)\n",
    "# ax2.imshow(n_img_canvas)\n",
    "\n",
    "transform = vo.get_transform(c_pnts_3d_cl, n_pnts_3d_cl, C_left, type_='PnP')\n",
    "# print(transform[:3,:3], transform[:3,3])\n",
    "# print(gt_pose_transform[:3,:3], gt_pose_transform[:3,3])\n",
    "\n",
    "n_pose = vo.get_next_pose(transform, c_pose)\n",
    "# print(n_pose[:3,:3])\n",
    "# print(n_pose[:3,3])\n",
    "\n",
    "pred_pose_transform = n_pose @ np.linalg.inv(c_pose)\n",
    "# print(pred_pose_transform[:3,:3], pred_pose_transform[:3,3])\n",
    "err = np.abs(gt_pose_transform-pred_pose_transform)\n",
    "print(err[:3,:3])\n",
    "print(err[:3,3])\n",
    "\n",
    "show_3d_features(c_pnts_3d_cl, n_pnts_3d_cl, C_left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
